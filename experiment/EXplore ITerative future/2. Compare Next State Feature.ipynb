{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "%matplotlib notebook\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_index(T, index):\n",
    "    return torch.cat([T[:i], T[i+1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MomentumObject:\n",
    "    def __init__(self, w, h):\n",
    "        self.w, self.h = w,h\n",
    "        self.position = np.array([w/2, h/2])\n",
    "        self.blank_state = np.zeros((w,h))\n",
    "        self.speed = np.random.randint(-2, 2, size=2)\n",
    "    def _jump_bound(self, position):\n",
    "        if position[0] >= self.w:\n",
    "            position[0] = position[0] - self.w\n",
    "        elif position[0] < 0:\n",
    "            position[0] = self.w + position[0]\n",
    "        if position[1] >= self.h:\n",
    "            position[1] = position[1] - self.w\n",
    "        elif position[1] < 0:\n",
    "            position[1] = self.h + position[1]\n",
    "    def get_state_action(self):\n",
    "        return np.concatenate((self.position, self.speed))\n",
    "    def step(self):\n",
    "        self.position += self.speed\n",
    "        self._jump_bound(self.position)\n",
    "        self.speed = np.random.randint(-2, 2, size=2)\n",
    "    def render(self, predict_position=None):\n",
    "        state = self.blank_state.copy()\n",
    "        position = np.round(self.position).astype(int)\n",
    "        state[position[0], position[1]] = 1\n",
    "        if predict_position is not None:\n",
    "            pred_x = np.round(predict_position[0]*(self.w-1)).astype(int)\n",
    "            pred_y = np.round(predict_position[1]*(self.h-1)).astype(int)\n",
    "            state[pred_x, pred_y] = 0.2\n",
    "        return state\n",
    "w,h=10,10\n",
    "momentum_object = MomentumObject(w, h)\n",
    "momentum_object.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  1.,  1., -1.],\n",
       "        [ 4.,  2., -2., -1.],\n",
       "        [ 6.,  4., -2., -2.],\n",
       "        [ 8.,  3., -2.,  1.],\n",
       "        [ 7.,  4.,  1., -1.],\n",
       "        [ 8.,  6., -1., -2.],\n",
       "        [ 0.,  6., -2.,  0.],\n",
       "        [ 2.,  6., -2.,  0.],\n",
       "        [ 4.,  8., -2., -2.],\n",
       "        [ 4.,  8.,  0.,  0.],\n",
       "        [ 4.,  7.,  0.,  1.],\n",
       "        [ 3.,  8.,  1., -1.],\n",
       "        [ 2.,  0.,  1., -2.],\n",
       "        [ 1.,  9.,  1.,  1.],\n",
       "        [ 1.,  0.,  0., -1.],\n",
       "        [ 2.,  1., -1., -1.],\n",
       "        [ 1.,  3.,  1., -2.],\n",
       "        [ 3.,  5., -2., -2.],\n",
       "        [ 5.,  6., -2., -1.],\n",
       "        [ 6.,  8., -1., -2.],\n",
       "        [ 8.,  0., -2., -2.],\n",
       "        [ 8.,  1.,  0., -1.],\n",
       "        [ 0.,  2., -2., -1.],\n",
       "        [ 1.,  3., -1., -1.],\n",
       "        [ 0.,  2.,  1.,  1.],\n",
       "        [ 2.,  4., -2., -2.],\n",
       "        [ 1.,  4.,  1.,  0.],\n",
       "        [ 3.,  4., -2.,  0.],\n",
       "        [ 4.,  3., -1.,  1.],\n",
       "        [ 3.,  3.,  1.,  0.],\n",
       "        [ 4.,  2., -1.,  1.],\n",
       "        [ 4.,  2.,  0.,  0.],\n",
       "        [ 4.,  2.,  0.,  0.],\n",
       "        [ 4.,  1.,  0.,  1.],\n",
       "        [ 4.,  0.,  0.,  1.],\n",
       "        [ 4.,  0.,  0.,  0.],\n",
       "        [ 4.,  2.,  0., -2.],\n",
       "        [ 3.,  2.,  1.,  0.],\n",
       "        [ 2.,  3.,  1., -1.],\n",
       "        [ 4.,  3., -2.,  0.],\n",
       "        [ 5.,  4., -1., -1.],\n",
       "        [ 7.,  5., -2., -1.],\n",
       "        [ 7.,  7.,  0., -2.],\n",
       "        [ 7.,  6.,  0.,  1.],\n",
       "        [ 6.,  8.,  1., -2.],\n",
       "        [ 5.,  8.,  1.,  0.],\n",
       "        [ 4.,  9.,  1., -1.],\n",
       "        [ 6.,  8., -2.,  1.],\n",
       "        [ 6.,  9.,  0., -1.],\n",
       "        [ 7.,  1., -1., -2.],\n",
       "        [ 7.,  2.,  0., -1.],\n",
       "        [ 9.,  1., -2.,  1.],\n",
       "        [ 1.,  1., -2.,  0.],\n",
       "        [ 3.,  2., -2., -1.],\n",
       "        [ 2.,  3.,  1., -1.],\n",
       "        [ 4.,  3., -2.,  0.],\n",
       "        [ 4.,  2.,  0.,  1.],\n",
       "        [ 5.,  3., -1., -1.],\n",
       "        [ 7.,  3., -2.,  0.],\n",
       "        [ 6.,  5.,  1., -2.],\n",
       "        [ 5.,  5.,  1.,  0.],\n",
       "        [ 5.,  4.,  0.,  1.],\n",
       "        [ 7.,  3., -2.,  1.],\n",
       "        [ 6.,  4.,  1., -1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_buffer = 64\n",
    "dimension_state = 2\n",
    "num_state = momentum_object.position.shape[0] + momentum_object.speed.shape[0]\n",
    "states_actions = torch.zeros((num_buffer, num_state))\n",
    "\n",
    "def update_state_buffer(states_actions, remove_index=None):\n",
    "    new_state_action = torch.unsqueeze(torch.tensor(momentum_object.get_state_action()), 0)\n",
    "    if remove_index is None:\n",
    "        states_actions = states_actions[:-1]\n",
    "    else:\n",
    "        states_actions = delete_index(states_actions, remove_index)\n",
    "    return torch.cat((new_state_action, states_actions))\n",
    "for i in range(num_buffer):\n",
    "    momentum_object.step()\n",
    "    states_actions=update_state_buffer(states_actions)\n",
    "states_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 0 ]: tensor(43.0607, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 1 ]: tensor(43.0707, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 2 ]: tensor(43.0443, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 3 ]: tensor(43.0556, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 4 ]: tensor(43.0047, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 5 ]: tensor(43.0248, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 6 ]: tensor(43.0536, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 7 ]: tensor(43.1228, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 8 ]: tensor(43.1565, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 9 ]: tensor(43.1488, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 10 ]: tensor(43.1187, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 11 ]: tensor(43.0604, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 12 ]: tensor(43.0260, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 13 ]: tensor(43.0936, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 14 ]: tensor(43.1876, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 15 ]: tensor(43.2369, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 16 ]: tensor(43.2759, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 17 ]: tensor(43.2574, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 18 ]: tensor(43.1999, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 19 ]: tensor(43.0846, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 20 ]: tensor(43.1240, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 21 ]: tensor(43.1237, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 22 ]: tensor(43.1847, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 23 ]: tensor(43.2647, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 24 ]: tensor(43.3606, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 25 ]: tensor(43.4461, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 26 ]: tensor(43.5139, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 27 ]: tensor(43.5514, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 28 ]: tensor(43.5859, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 29 ]: tensor(43.6135, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 30 ]: tensor(43.6137, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 31 ]: tensor(43.6248, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 32 ]: tensor(43.6329, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 33 ]: tensor(43.6431, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 34 ]: tensor(43.6580, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 35 ]: tensor(43.6668, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 36 ]: tensor(43.6776, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 37 ]: tensor(43.6767, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 38 ]: tensor(43.6855, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 39 ]: tensor(43.5931, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 40 ]: tensor(43.5540, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 41 ]: tensor(43.5675, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 42 ]: tensor(43.5758, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 43 ]: tensor(43.5715, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 44 ]: tensor(43.5642, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 45 ]: tensor(43.5435, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 46 ]: tensor(43.5204, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 47 ]: tensor(43.5349, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 48 ]: tensor(43.5880, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 49 ]: tensor(43.6296, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 50 ]: tensor(43.6556, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 51 ]: tensor(43.6297, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 52 ]: tensor(43.5761, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 53 ]: tensor(43.6116, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 54 ]: tensor(43.6484, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 55 ]: tensor(43.6813, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 56 ]: tensor(43.6878, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 57 ]: tensor(43.7128, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 58 ]: tensor(43.7515, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 59 ]: tensor(43.7775, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 60 ]: tensor(43.8115, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 61 ]: tensor(43.8339, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 62 ]: tensor(43.8640, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 63 ]: tensor(43.8778, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 64 ]: tensor(43.8527, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 65 ]: tensor(43.8299, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 66 ]: tensor(43.8041, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 67 ]: tensor(43.7353, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 68 ]: tensor(43.6344, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 69 ]: tensor(43.6959, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 70 ]: tensor(43.7543, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 71 ]: tensor(43.8158, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 72 ]: tensor(43.8772, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 73 ]: tensor(43.9287, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 74 ]: tensor(43.9709, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 75 ]: tensor(43.9959, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 76 ]: tensor(43.9948, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 77 ]: tensor(43.9645, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 78 ]: tensor(43.9150, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 79 ]: tensor(43.8533, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 80 ]: tensor(43.8926, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 81 ]: tensor(43.9544, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 82 ]: tensor(44.0077, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 83 ]: tensor(44.0922, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 84 ]: tensor(44.1383, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 85 ]: tensor(44.1592, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 86 ]: tensor(44.1599, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 87 ]: tensor(44.1383, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 88 ]: tensor(44.1215, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 89 ]: tensor(44.0777, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 90 ]: tensor(44.0769, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 91 ]: tensor(44.0676, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 92 ]: tensor(44.0545, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 93 ]: tensor(44.0480, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 94 ]: tensor(44.0415, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 95 ]: tensor(44.0083, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 96 ]: tensor(43.9644, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 97 ]: tensor(43.9204, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 98 ]: tensor(43.9175, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 99 ]: tensor(43.8944, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 100 ]: tensor(43.8821, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 101 ]: tensor(43.8786, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 102 ]: tensor(43.9058, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 103 ]: tensor(43.9504, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 104 ]: tensor(43.9980, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 105 ]: tensor(44.0651, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 106 ]: tensor(44.1411, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 107 ]: tensor(44.1435, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 108 ]: tensor(44.0906, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 109 ]: tensor(44.0275, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 110 ]: tensor(44.0296, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 111 ]: tensor(44.0335, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 112 ]: tensor(44.0299, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 113 ]: tensor(44.0353, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 114 ]: tensor(44.0530, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 115 ]: tensor(44.0620, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 116 ]: tensor(44.0524, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 117 ]: tensor(44.0284, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 118 ]: tensor(43.9766, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 119 ]: tensor(43.9252, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 120 ]: tensor(43.8651, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 121 ]: tensor(43.7758, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 122 ]: tensor(43.7636, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 123 ]: tensor(43.7549, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 124 ]: tensor(43.7686, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 125 ]: tensor(43.8140, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 126 ]: tensor(43.8765, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 127 ]: tensor(43.9214, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 128 ]: tensor(43.9292, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 129 ]: tensor(43.9248, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 130 ]: tensor(43.9253, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 131 ]: tensor(43.9201, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 132 ]: tensor(43.9224, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 133 ]: tensor(43.9050, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 134 ]: tensor(43.8870, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 135 ]: tensor(43.9070, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 136 ]: tensor(43.9898, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 137 ]: tensor(44.0471, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 138 ]: tensor(44.0711, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 139 ]: tensor(44.0696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 140 ]: tensor(44.0322, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 141 ]: tensor(43.9501, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 142 ]: tensor(43.8651, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 143 ]: tensor(43.7918, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 144 ]: tensor(43.7887, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 145 ]: tensor(43.7646, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 146 ]: tensor(43.7464, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 147 ]: tensor(43.7151, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 148 ]: tensor(43.6557, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 149 ]: tensor(43.5924, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 150 ]: tensor(43.6131, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 151 ]: tensor(43.5955, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 152 ]: tensor(43.5615, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 153 ]: tensor(43.5279, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 154 ]: tensor(43.5034, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 155 ]: tensor(43.4899, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 156 ]: tensor(43.4403, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 157 ]: tensor(43.4547, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 158 ]: tensor(43.5273, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 159 ]: tensor(43.5859, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 160 ]: tensor(43.5788, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 161 ]: tensor(43.6661, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 162 ]: tensor(43.7032, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 163 ]: tensor(43.7475, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 164 ]: tensor(43.8462, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 165 ]: tensor(43.8579, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 166 ]: tensor(43.9319, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 167 ]: tensor(43.9889, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 168 ]: tensor(44.0101, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 169 ]: tensor(44.0779, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 170 ]: tensor(44.1329, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 171 ]: tensor(44.1750, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 172 ]: tensor(44.1893, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 173 ]: tensor(44.1922, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 174 ]: tensor(44.1753, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 175 ]: tensor(44.1652, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 176 ]: tensor(44.1563, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 177 ]: tensor(44.1388, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 178 ]: tensor(44.1041, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 179 ]: tensor(44.0212, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 180 ]: tensor(43.9516, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 181 ]: tensor(43.9247, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 182 ]: tensor(43.9119, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 183 ]: tensor(43.9190, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 184 ]: tensor(43.9820, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 185 ]: tensor(44.0515, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 186 ]: tensor(44.0555, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 187 ]: tensor(44.1143, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 188 ]: tensor(44.1558, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 189 ]: tensor(44.1943, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 190 ]: tensor(44.2342, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 191 ]: tensor(44.2592, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 192 ]: tensor(44.2768, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 193 ]: tensor(44.2984, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 194 ]: tensor(44.3154, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 195 ]: tensor(44.3245, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 196 ]: tensor(44.3338, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 197 ]: tensor(44.3147, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 198 ]: tensor(44.3592, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 199 ]: tensor(44.4117, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 200 ]: tensor(44.4483, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 201 ]: tensor(44.4629, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 202 ]: tensor(44.4544, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 203 ]: tensor(44.4263, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 204 ]: tensor(44.3489, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 205 ]: tensor(44.3752, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 206 ]: tensor(44.3439, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 207 ]: tensor(44.3137, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 208 ]: tensor(44.2575, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 209 ]: tensor(44.2246, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 210 ]: tensor(44.1966, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 211 ]: tensor(44.1170, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 212 ]: tensor(44.0211, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 213 ]: tensor(44.0224, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 214 ]: tensor(44.1039, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 215 ]: tensor(44.1773, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 216 ]: tensor(44.2417, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 217 ]: tensor(44.3276, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 218 ]: tensor(44.4262, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 219 ]: tensor(44.5021, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 220 ]: tensor(44.5548, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 221 ]: tensor(44.5775, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 222 ]: tensor(44.5691, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 223 ]: tensor(44.5665, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 224 ]: tensor(44.5521, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 225 ]: tensor(44.5032, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 226 ]: tensor(44.4075, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 227 ]: tensor(44.2984, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 228 ]: tensor(44.2610, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 229 ]: tensor(44.3027, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 230 ]: tensor(44.3172, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 231 ]: tensor(44.3070, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 232 ]: tensor(44.3182, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 233 ]: tensor(44.3199, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 234 ]: tensor(44.3085, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 235 ]: tensor(44.3440, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 236 ]: tensor(44.4087, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 237 ]: tensor(44.4336, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 238 ]: tensor(44.4140, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 239 ]: tensor(44.3494, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 240 ]: tensor(44.4066, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 241 ]: tensor(44.4715, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 242 ]: tensor(44.5268, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 243 ]: tensor(44.5917, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 244 ]: tensor(44.6655, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 245 ]: tensor(44.7399, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 246 ]: tensor(44.7831, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 247 ]: tensor(44.8197, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 248 ]: tensor(44.8444, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 249 ]: tensor(44.8808, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 250 ]: tensor(44.9011, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 251 ]: tensor(44.8893, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 252 ]: tensor(44.8734, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 253 ]: tensor(44.9001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 254 ]: tensor(44.9321, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 255 ]: tensor(44.9383, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 256 ]: tensor(44.9328, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 257 ]: tensor(44.9339, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 258 ]: tensor(44.9134, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 259 ]: tensor(44.9079, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 260 ]: tensor(44.9181, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 261 ]: tensor(44.9218, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 262 ]: tensor(44.9128, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 263 ]: tensor(44.9170, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 264 ]: tensor(44.9216, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 265 ]: tensor(44.8360, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 266 ]: tensor(44.7241, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 267 ]: tensor(44.6901, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 268 ]: tensor(44.7000, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 269 ]: tensor(44.6838, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 270 ]: tensor(44.7349, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 271 ]: tensor(44.7215, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 272 ]: tensor(44.7369, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 273 ]: tensor(44.7220, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 274 ]: tensor(44.7535, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 275 ]: tensor(44.8684, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 276 ]: tensor(44.9006, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 277 ]: tensor(44.9700, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 278 ]: tensor(45.0095, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 279 ]: tensor(45.0255, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 280 ]: tensor(44.9661, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 281 ]: tensor(44.9186, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 282 ]: tensor(44.8799, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 283 ]: tensor(44.8797, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 284 ]: tensor(44.8725, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 285 ]: tensor(44.9280, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 286 ]: tensor(44.9704, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 287 ]: tensor(44.9752, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 288 ]: tensor(44.9561, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 289 ]: tensor(45.0025, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 290 ]: tensor(45.0661, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 291 ]: tensor(45.0765, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 292 ]: tensor(45.0558, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 293 ]: tensor(45.0080, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 294 ]: tensor(44.9379, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 295 ]: tensor(44.9498, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 296 ]: tensor(44.9063, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 297 ]: tensor(44.9298, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 298 ]: tensor(44.9250, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 299 ]: tensor(44.8896, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 300 ]: tensor(44.8243, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 301 ]: tensor(44.8054, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 302 ]: tensor(44.8054, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 303 ]: tensor(44.7947, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 304 ]: tensor(44.7706, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 305 ]: tensor(44.7523, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 306 ]: tensor(44.7504, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 307 ]: tensor(44.7551, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 308 ]: tensor(44.7324, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 309 ]: tensor(44.7626, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 310 ]: tensor(44.7721, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 311 ]: tensor(44.7595, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 312 ]: tensor(44.7548, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 313 ]: tensor(44.7609, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 314 ]: tensor(44.7057, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 315 ]: tensor(44.7401, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 316 ]: tensor(44.7928, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 317 ]: tensor(44.8215, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 318 ]: tensor(44.8377, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 319 ]: tensor(44.8319, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 320 ]: tensor(44.8101, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 321 ]: tensor(44.7622, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 322 ]: tensor(44.6871, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 323 ]: tensor(44.6724, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 324 ]: tensor(44.6629, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 325 ]: tensor(44.6561, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 326 ]: tensor(44.6598, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 327 ]: tensor(44.6549, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 328 ]: tensor(44.6446, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 329 ]: tensor(44.6784, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 330 ]: tensor(44.6606, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 331 ]: tensor(44.6129, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 332 ]: tensor(44.6134, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 333 ]: tensor(44.5790, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 334 ]: tensor(44.6143, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 335 ]: tensor(44.7135, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 336 ]: tensor(44.8323, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 337 ]: tensor(44.9169, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 338 ]: tensor(44.9708, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 339 ]: tensor(45.0344, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 340 ]: tensor(45.0966, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 341 ]: tensor(45.1602, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 342 ]: tensor(45.2161, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 343 ]: tensor(45.2303, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 344 ]: tensor(45.2406, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 345 ]: tensor(45.2607, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 346 ]: tensor(45.2313, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 347 ]: tensor(45.2030, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 348 ]: tensor(45.1968, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 349 ]: tensor(45.1875, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 350 ]: tensor(45.1814, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 351 ]: tensor(45.1551, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 352 ]: tensor(45.1487, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 353 ]: tensor(45.1396, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 354 ]: tensor(45.1186, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 355 ]: tensor(45.1207, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 356 ]: tensor(45.1539, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 357 ]: tensor(45.1937, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 358 ]: tensor(45.1664, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 359 ]: tensor(45.2091, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 360 ]: tensor(45.2373, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 361 ]: tensor(45.2624, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 362 ]: tensor(45.2758, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 363 ]: tensor(45.2670, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 364 ]: tensor(45.2241, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 365 ]: tensor(45.2485, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 366 ]: tensor(45.2510, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 367 ]: tensor(45.2158, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 368 ]: tensor(45.1429, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 369 ]: tensor(45.1163, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 370 ]: tensor(45.0871, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 371 ]: tensor(45.0234, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 372 ]: tensor(44.9489, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 373 ]: tensor(44.8741, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 374 ]: tensor(44.8712, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 375 ]: tensor(44.8311, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 376 ]: tensor(44.8289, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 377 ]: tensor(44.8552, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 378 ]: tensor(44.8827, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 379 ]: tensor(44.8593, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 380 ]: tensor(44.7629, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 381 ]: tensor(44.7098, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 382 ]: tensor(44.6696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 383 ]: tensor(44.6199, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 384 ]: tensor(44.5506, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 385 ]: tensor(44.5514, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 386 ]: tensor(44.5829, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 387 ]: tensor(44.6455, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 388 ]: tensor(44.6774, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 389 ]: tensor(44.6901, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 390 ]: tensor(44.6711, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 391 ]: tensor(44.6260, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 392 ]: tensor(44.6074, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 393 ]: tensor(44.5818, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 394 ]: tensor(44.5979, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 395 ]: tensor(44.5770, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 396 ]: tensor(44.6099, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 397 ]: tensor(44.6186, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 398 ]: tensor(44.6047, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 399 ]: tensor(44.6081, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 400 ]: tensor(44.6024, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 401 ]: tensor(44.6025, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 402 ]: tensor(44.6027, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 403 ]: tensor(44.5786, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 404 ]: tensor(44.5772, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 405 ]: tensor(44.5072, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 406 ]: tensor(44.5083, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 407 ]: tensor(44.5302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 408 ]: tensor(44.5583, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 409 ]: tensor(44.5649, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 410 ]: tensor(44.5607, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 411 ]: tensor(44.5988, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 412 ]: tensor(44.6630, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 413 ]: tensor(44.7242, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 414 ]: tensor(44.7522, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 415 ]: tensor(44.7547, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 416 ]: tensor(44.8301, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 417 ]: tensor(44.8774, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 418 ]: tensor(44.9240, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 419 ]: tensor(44.9212, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 420 ]: tensor(44.9039, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 421 ]: tensor(44.9170, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 422 ]: tensor(44.9396, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 423 ]: tensor(44.9431, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 424 ]: tensor(44.9327, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 425 ]: tensor(44.8861, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 426 ]: tensor(44.8300, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 427 ]: tensor(44.7766, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 428 ]: tensor(44.7285, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 429 ]: tensor(44.7017, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 430 ]: tensor(44.6826, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 431 ]: tensor(44.6684, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 432 ]: tensor(44.6058, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 433 ]: tensor(44.5484, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 434 ]: tensor(44.5289, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 435 ]: tensor(44.4798, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 436 ]: tensor(44.4466, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 437 ]: tensor(44.5287, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 438 ]: tensor(44.5451, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 439 ]: tensor(44.6121, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 440 ]: tensor(44.6686, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 441 ]: tensor(44.7151, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 442 ]: tensor(44.7444, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 443 ]: tensor(44.7615, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 444 ]: tensor(44.8031, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 445 ]: tensor(44.8487, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 446 ]: tensor(44.8552, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 447 ]: tensor(44.8237, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 448 ]: tensor(44.7821, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 449 ]: tensor(44.8298, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 450 ]: tensor(44.8174, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 451 ]: tensor(44.7680, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 452 ]: tensor(44.8063, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 453 ]: tensor(44.8719, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 454 ]: tensor(44.9382, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 455 ]: tensor(44.9801, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 456 ]: tensor(45.0106, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 457 ]: tensor(45.0353, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 458 ]: tensor(45.0253, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 459 ]: tensor(45.0373, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 460 ]: tensor(45.0549, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 461 ]: tensor(45.0741, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 462 ]: tensor(45.1077, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 463 ]: tensor(45.1251, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 464 ]: tensor(45.1472, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 465 ]: tensor(45.1511, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 466 ]: tensor(45.1732, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 467 ]: tensor(45.1790, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 468 ]: tensor(45.1734, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 469 ]: tensor(45.1387, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 470 ]: tensor(45.1512, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 471 ]: tensor(45.1771, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 472 ]: tensor(45.2107, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 473 ]: tensor(45.1447, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 474 ]: tensor(45.0801, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 475 ]: tensor(45.1153, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 476 ]: tensor(45.1710, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 477 ]: tensor(45.1688, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 478 ]: tensor(45.1699, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 479 ]: tensor(45.2178, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 480 ]: tensor(45.2773, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 481 ]: tensor(45.2979, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 482 ]: tensor(45.2943, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 483 ]: tensor(45.2779, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 484 ]: tensor(45.3475, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 485 ]: tensor(45.4477, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 486 ]: tensor(45.5339, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 487 ]: tensor(45.5950, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 488 ]: tensor(45.6269, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 489 ]: tensor(45.6378, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 490 ]: tensor(45.6602, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 491 ]: tensor(45.6572, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 492 ]: tensor(45.6625, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 493 ]: tensor(45.7112, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 494 ]: tensor(45.7238, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 495 ]: tensor(45.7068, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 496 ]: tensor(45.6956, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 497 ]: tensor(45.6774, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 498 ]: tensor(45.6143, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 499 ]: tensor(45.6148, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 500 ]: tensor(45.6239, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 501 ]: tensor(45.6327, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 502 ]: tensor(45.6282, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 503 ]: tensor(45.6341, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 504 ]: tensor(45.6809, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 505 ]: tensor(45.5650, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 506 ]: tensor(45.5251, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 507 ]: tensor(45.5309, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 508 ]: tensor(45.5311, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 509 ]: tensor(45.5527, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 510 ]: tensor(45.5844, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 511 ]: tensor(45.6056, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 512 ]: tensor(45.6072, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 513 ]: tensor(45.5778, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 514 ]: tensor(45.5886, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 515 ]: tensor(45.6505, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 516 ]: tensor(45.6971, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 517 ]: tensor(45.7351, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 518 ]: tensor(45.7736, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 519 ]: tensor(45.7804, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 520 ]: tensor(45.7654, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 521 ]: tensor(45.8111, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 522 ]: tensor(45.8254, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 523 ]: tensor(45.7429, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 524 ]: tensor(45.7717, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 525 ]: tensor(45.8120, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 526 ]: tensor(45.8279, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 527 ]: tensor(45.8584, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 528 ]: tensor(45.8672, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 529 ]: tensor(45.8649, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 530 ]: tensor(45.8348, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 531 ]: tensor(45.9139, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 532 ]: tensor(45.9785, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 533 ]: tensor(45.9917, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 534 ]: tensor(45.9786, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 535 ]: tensor(45.9394, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 536 ]: tensor(45.8928, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 537 ]: tensor(45.8395, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 538 ]: tensor(45.7855, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 539 ]: tensor(45.7305, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 540 ]: tensor(45.6773, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 541 ]: tensor(45.6223, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 542 ]: tensor(45.5481, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 543 ]: tensor(45.5371, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 544 ]: tensor(45.5529, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 545 ]: tensor(45.6229, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 546 ]: tensor(45.6916, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 547 ]: tensor(45.6964, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 548 ]: tensor(45.7633, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 549 ]: tensor(45.8095, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 550 ]: tensor(45.7436, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 551 ]: tensor(45.7191, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 552 ]: tensor(45.7023, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 553 ]: tensor(45.6942, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 554 ]: tensor(45.6905, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 555 ]: tensor(45.6955, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 556 ]: tensor(45.7069, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 557 ]: tensor(45.6542, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 558 ]: tensor(45.5834, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 559 ]: tensor(45.4813, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 560 ]: tensor(45.4463, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 561 ]: tensor(45.3888, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 562 ]: tensor(45.3272, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 563 ]: tensor(45.3307, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 564 ]: tensor(45.3447, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 565 ]: tensor(45.3487, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 566 ]: tensor(45.3597, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 567 ]: tensor(45.3795, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 568 ]: tensor(45.3749, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 569 ]: tensor(45.3539, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 570 ]: tensor(45.3331, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 571 ]: tensor(45.2985, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 572 ]: tensor(45.2797, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 573 ]: tensor(45.2771, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 574 ]: tensor(45.2918, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 575 ]: tensor(45.3030, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 576 ]: tensor(45.3112, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 577 ]: tensor(45.2898, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 578 ]: tensor(45.2432, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 579 ]: tensor(45.1787, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 580 ]: tensor(45.1288, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 581 ]: tensor(45.0897, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 582 ]: tensor(45.1044, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 583 ]: tensor(45.0743, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 584 ]: tensor(45.0904, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 585 ]: tensor(45.1050, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 586 ]: tensor(45.0687, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 587 ]: tensor(45.0813, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 588 ]: tensor(45.0759, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 589 ]: tensor(45.0619, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 590 ]: tensor(45.0305, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 591 ]: tensor(45.0052, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 592 ]: tensor(45.0136, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 593 ]: tensor(45.0464, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 594 ]: tensor(45.0526, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 595 ]: tensor(44.9295, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 596 ]: tensor(44.8759, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 597 ]: tensor(44.7674, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 598 ]: tensor(44.6929, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 599 ]: tensor(44.6593, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 600 ]: tensor(44.6945, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 601 ]: tensor(44.6254, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 602 ]: tensor(44.6253, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 603 ]: tensor(44.6548, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 604 ]: tensor(44.6541, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 605 ]: tensor(44.7166, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 606 ]: tensor(44.6942, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 607 ]: tensor(44.6572, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 608 ]: tensor(44.6757, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 609 ]: tensor(44.6573, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 610 ]: tensor(44.6368, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 611 ]: tensor(44.6349, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 612 ]: tensor(44.6132, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 613 ]: tensor(44.6502, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 614 ]: tensor(44.6662, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 615 ]: tensor(44.6701, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 616 ]: tensor(44.6636, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 617 ]: tensor(44.6535, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 618 ]: tensor(44.6463, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 619 ]: tensor(44.6124, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 620 ]: tensor(44.5883, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 621 ]: tensor(44.5648, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 622 ]: tensor(44.5299, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 623 ]: tensor(44.4826, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 624 ]: tensor(44.4815, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 625 ]: tensor(44.4570, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 626 ]: tensor(44.3971, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 627 ]: tensor(44.4026, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 628 ]: tensor(44.3952, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 629 ]: tensor(44.3422, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 630 ]: tensor(44.3762, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 631 ]: tensor(44.3845, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 632 ]: tensor(44.3749, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 633 ]: tensor(44.4328, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 634 ]: tensor(44.5164, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 635 ]: tensor(44.5927, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 636 ]: tensor(44.6229, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 637 ]: tensor(44.6070, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 638 ]: tensor(44.5514, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 639 ]: tensor(44.5562, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 640 ]: tensor(44.5528, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 641 ]: tensor(44.5379, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 642 ]: tensor(44.5045, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 643 ]: tensor(44.5232, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 644 ]: tensor(44.5791, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 645 ]: tensor(44.5709, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 646 ]: tensor(44.5211, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 647 ]: tensor(44.4448, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 648 ]: tensor(44.5050, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 649 ]: tensor(44.4915, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 650 ]: tensor(44.4881, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 651 ]: tensor(44.5067, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 652 ]: tensor(44.5169, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 653 ]: tensor(44.4980, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 654 ]: tensor(44.5175, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 655 ]: tensor(44.5549, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 656 ]: tensor(44.5753, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 657 ]: tensor(44.5893, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 658 ]: tensor(44.6122, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 659 ]: tensor(44.6255, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 660 ]: tensor(44.6139, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 661 ]: tensor(44.5991, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 662 ]: tensor(44.5872, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 663 ]: tensor(44.5719, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 664 ]: tensor(44.5176, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 665 ]: tensor(44.4882, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 666 ]: tensor(44.4594, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 667 ]: tensor(44.4573, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 668 ]: tensor(44.4781, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 669 ]: tensor(44.5877, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 670 ]: tensor(44.6567, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 671 ]: tensor(44.6052, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 672 ]: tensor(44.6157, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 673 ]: tensor(44.5497, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 674 ]: tensor(44.5563, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 675 ]: tensor(44.4846, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 676 ]: tensor(44.4894, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 677 ]: tensor(44.4976, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 678 ]: tensor(44.5010, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 679 ]: tensor(44.5352, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 680 ]: tensor(44.5843, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 681 ]: tensor(44.6467, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 682 ]: tensor(44.7034, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 683 ]: tensor(44.7302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 684 ]: tensor(44.7369, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 685 ]: tensor(44.7366, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 686 ]: tensor(44.8104, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 687 ]: tensor(44.8842, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 688 ]: tensor(44.9612, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 689 ]: tensor(45.0028, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 690 ]: tensor(45.0153, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 691 ]: tensor(45.0385, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 692 ]: tensor(45.0444, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 693 ]: tensor(45.0325, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 694 ]: tensor(44.9863, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 695 ]: tensor(44.9877, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 696 ]: tensor(44.9802, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 697 ]: tensor(44.9626, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 698 ]: tensor(44.9474, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 699 ]: tensor(44.9433, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 700 ]: tensor(44.9494, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 701 ]: tensor(44.9484, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 702 ]: tensor(44.9739, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 703 ]: tensor(45.0235, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 704 ]: tensor(45.0264, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 705 ]: tensor(44.9931, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 706 ]: tensor(44.9548, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 707 ]: tensor(44.9546, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 708 ]: tensor(44.9387, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 709 ]: tensor(44.9113, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 710 ]: tensor(44.9121, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 711 ]: tensor(44.8947, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 712 ]: tensor(44.8708, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 713 ]: tensor(44.8596, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 714 ]: tensor(44.8389, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 715 ]: tensor(44.8863, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 716 ]: tensor(44.9536, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 717 ]: tensor(44.9444, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 718 ]: tensor(45.0298, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 719 ]: tensor(45.0780, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 720 ]: tensor(45.1261, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 721 ]: tensor(45.1791, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 722 ]: tensor(45.2174, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 723 ]: tensor(45.2375, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 724 ]: tensor(45.2317, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 725 ]: tensor(45.1931, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 726 ]: tensor(45.1517, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 727 ]: tensor(45.1062, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 728 ]: tensor(45.0415, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 729 ]: tensor(44.9271, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 730 ]: tensor(44.8892, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 731 ]: tensor(44.8832, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 732 ]: tensor(44.8789, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 733 ]: tensor(44.8328, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 734 ]: tensor(44.7871, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 735 ]: tensor(44.7302, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 736 ]: tensor(44.6293, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 737 ]: tensor(44.5838, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 738 ]: tensor(44.5899, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 739 ]: tensor(44.5910, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 740 ]: tensor(44.6515, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 741 ]: tensor(44.7626, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 742 ]: tensor(44.8401, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 743 ]: tensor(44.8149, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 744 ]: tensor(44.7789, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 745 ]: tensor(44.7613, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 746 ]: tensor(44.8156, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 747 ]: tensor(44.8675, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 748 ]: tensor(44.8941, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 749 ]: tensor(44.8829, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 750 ]: tensor(44.8677, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 751 ]: tensor(44.8374, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 752 ]: tensor(44.8128, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 753 ]: tensor(44.7993, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 754 ]: tensor(44.8358, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 755 ]: tensor(44.8856, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 756 ]: tensor(44.9326, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 757 ]: tensor(44.9682, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 758 ]: tensor(45.0066, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 759 ]: tensor(45.0327, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 760 ]: tensor(45.0239, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 761 ]: tensor(44.9807, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 762 ]: tensor(44.9327, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 763 ]: tensor(44.8360, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 764 ]: tensor(44.7759, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 765 ]: tensor(44.7723, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 766 ]: tensor(44.6371, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 767 ]: tensor(44.5714, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 768 ]: tensor(44.5024, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 769 ]: tensor(44.4758, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 770 ]: tensor(44.4821, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 771 ]: tensor(44.5428, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 772 ]: tensor(44.6593, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 773 ]: tensor(44.7742, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 774 ]: tensor(44.8891, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 775 ]: tensor(44.9738, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 776 ]: tensor(45.0193, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 777 ]: tensor(45.0231, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 778 ]: tensor(45.0251, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 779 ]: tensor(45.0048, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 780 ]: tensor(44.9893, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 781 ]: tensor(44.9696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 782 ]: tensor(44.9596, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 783 ]: tensor(44.9752, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 784 ]: tensor(45.0067, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 785 ]: tensor(45.0621, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 786 ]: tensor(45.1151, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 787 ]: tensor(45.1816, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 788 ]: tensor(45.2441, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 789 ]: tensor(45.2916, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 790 ]: tensor(45.3386, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 791 ]: tensor(45.3766, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 792 ]: tensor(45.4121, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 793 ]: tensor(45.4415, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 794 ]: tensor(45.4701, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 795 ]: tensor(45.5016, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 796 ]: tensor(45.5244, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 797 ]: tensor(45.5441, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 798 ]: tensor(45.5602, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 799 ]: tensor(45.5689, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 800 ]: tensor(45.5640, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 801 ]: tensor(45.5605, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 802 ]: tensor(45.5415, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 803 ]: tensor(45.5081, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 804 ]: tensor(45.5066, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 805 ]: tensor(45.5717, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 806 ]: tensor(45.6208, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 807 ]: tensor(45.6234, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 808 ]: tensor(45.6393, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 809 ]: tensor(45.6571, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 810 ]: tensor(45.7257, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 811 ]: tensor(45.7879, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 812 ]: tensor(45.8702, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 813 ]: tensor(45.9607, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 814 ]: tensor(46.0057, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 815 ]: tensor(46.0001, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 816 ]: tensor(46.0407, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 817 ]: tensor(46.0696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 818 ]: tensor(46.0808, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 819 ]: tensor(46.0837, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 820 ]: tensor(46.1016, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 821 ]: tensor(46.1306, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 822 ]: tensor(46.1163, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 823 ]: tensor(46.0527, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 824 ]: tensor(46.0334, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 825 ]: tensor(46.0281, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 826 ]: tensor(46.0585, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 827 ]: tensor(46.0653, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 828 ]: tensor(46.0742, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 829 ]: tensor(46.1096, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 830 ]: tensor(46.1182, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 831 ]: tensor(46.1843, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 832 ]: tensor(46.2217, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 833 ]: tensor(46.2539, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 834 ]: tensor(46.2158, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 835 ]: tensor(46.1702, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 836 ]: tensor(46.1132, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 837 ]: tensor(46.0442, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 838 ]: tensor(46.0358, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 839 ]: tensor(46.0322, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 840 ]: tensor(46.0652, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 841 ]: tensor(46.1179, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 842 ]: tensor(46.1844, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 843 ]: tensor(46.2468, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 844 ]: tensor(46.3031, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 845 ]: tensor(46.3641, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 846 ]: tensor(46.4051, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 847 ]: tensor(46.4169, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 848 ]: tensor(46.4056, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 849 ]: tensor(46.3724, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 850 ]: tensor(46.3326, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 851 ]: tensor(46.3313, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 852 ]: tensor(46.2794, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 853 ]: tensor(46.2237, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 854 ]: tensor(46.2120, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 855 ]: tensor(46.1749, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 856 ]: tensor(46.1193, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 857 ]: tensor(46.1113, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 858 ]: tensor(46.1518, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 859 ]: tensor(46.1320, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 860 ]: tensor(46.1343, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 861 ]: tensor(46.0918, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 862 ]: tensor(46.0043, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 863 ]: tensor(45.9996, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 864 ]: tensor(45.9306, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 865 ]: tensor(45.9403, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 866 ]: tensor(45.9769, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 867 ]: tensor(45.9806, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 868 ]: tensor(45.9801, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 869 ]: tensor(45.9838, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 870 ]: tensor(45.9804, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 871 ]: tensor(45.9850, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 872 ]: tensor(45.9918, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 873 ]: tensor(45.9994, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 874 ]: tensor(46.0554, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 875 ]: tensor(46.0967, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 876 ]: tensor(46.1029, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 877 ]: tensor(46.1509, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 878 ]: tensor(46.1807, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 879 ]: tensor(46.1653, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 880 ]: tensor(46.0986, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 881 ]: tensor(45.9934, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 882 ]: tensor(45.8709, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 883 ]: tensor(45.8128, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 884 ]: tensor(45.7793, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 885 ]: tensor(45.7774, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 886 ]: tensor(45.7761, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 887 ]: tensor(45.7763, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 888 ]: tensor(45.7716, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 889 ]: tensor(45.7680, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 890 ]: tensor(45.7919, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 891 ]: tensor(45.8315, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 892 ]: tensor(45.8417, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 893 ]: tensor(45.8357, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 894 ]: tensor(45.8191, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 895 ]: tensor(45.7964, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 896 ]: tensor(45.7834, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 897 ]: tensor(45.7545, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 898 ]: tensor(45.7013, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 899 ]: tensor(45.6832, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 900 ]: tensor(45.6613, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 901 ]: tensor(45.6123, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 902 ]: tensor(45.5347, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 903 ]: tensor(45.4537, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 904 ]: tensor(45.4216, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 905 ]: tensor(45.4081, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 906 ]: tensor(45.3194, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 907 ]: tensor(45.2502, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 908 ]: tensor(45.2508, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 909 ]: tensor(45.2515, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 910 ]: tensor(45.2506, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 911 ]: tensor(45.3603, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 912 ]: tensor(45.4540, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 913 ]: tensor(45.5463, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 914 ]: tensor(45.6091, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 915 ]: tensor(45.6578, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 916 ]: tensor(45.7144, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 917 ]: tensor(45.7623, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 918 ]: tensor(45.7663, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 919 ]: tensor(45.7531, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 920 ]: tensor(45.7376, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 921 ]: tensor(45.7308, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 922 ]: tensor(45.7455, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 923 ]: tensor(45.7542, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 924 ]: tensor(45.7691, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 925 ]: tensor(45.8062, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 926 ]: tensor(45.8367, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 927 ]: tensor(45.8023, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 928 ]: tensor(45.7367, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 929 ]: tensor(45.6964, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 930 ]: tensor(45.6746, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 931 ]: tensor(45.6251, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 932 ]: tensor(45.5560, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 933 ]: tensor(45.4733, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 934 ]: tensor(45.3770, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 935 ]: tensor(45.2806, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 936 ]: tensor(45.1843, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 937 ]: tensor(45.0927, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 938 ]: tensor(45.0525, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 939 ]: tensor(45.0329, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 940 ]: tensor(45.0756, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 941 ]: tensor(45.0582, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 942 ]: tensor(45.1236, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 943 ]: tensor(45.1850, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 944 ]: tensor(45.2265, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 945 ]: tensor(45.2105, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 946 ]: tensor(45.2152, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 947 ]: tensor(45.1999, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 948 ]: tensor(45.2357, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 949 ]: tensor(45.2669, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 950 ]: tensor(45.3019, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 951 ]: tensor(45.3761, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 952 ]: tensor(45.4700, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 953 ]: tensor(45.5396, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 954 ]: tensor(45.6082, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 955 ]: tensor(45.6426, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 956 ]: tensor(45.5779, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 957 ]: tensor(45.6103, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 958 ]: tensor(45.6643, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 959 ]: tensor(45.6887, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 960 ]: tensor(45.7684, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 961 ]: tensor(45.8354, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 962 ]: tensor(45.8843, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 963 ]: tensor(45.9303, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 964 ]: tensor(45.9696, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 965 ]: tensor(45.9910, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 966 ]: tensor(46.0021, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 967 ]: tensor(45.9853, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 968 ]: tensor(45.9739, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 969 ]: tensor(45.9295, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 970 ]: tensor(45.8943, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 971 ]: tensor(45.8336, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss[ 972 ]: tensor(45.8428, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 973 ]: tensor(45.8510, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 974 ]: tensor(45.8475, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 975 ]: tensor(45.8697, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 976 ]: tensor(45.8888, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 977 ]: tensor(45.8935, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 978 ]: tensor(45.9065, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 979 ]: tensor(45.8806, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 980 ]: tensor(45.8917, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 981 ]: tensor(45.9064, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 982 ]: tensor(45.9148, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 983 ]: tensor(45.9016, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 984 ]: tensor(45.8617, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 985 ]: tensor(45.8158, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 986 ]: tensor(45.7701, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 987 ]: tensor(45.7201, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 988 ]: tensor(45.6489, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 989 ]: tensor(45.5896, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 990 ]: tensor(45.5097, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 991 ]: tensor(45.4789, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 992 ]: tensor(45.5085, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 993 ]: tensor(45.5455, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 994 ]: tensor(45.5807, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 995 ]: tensor(45.6014, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 996 ]: tensor(45.6049, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 997 ]: tensor(45.5102, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 998 ]: tensor(45.4224, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "loss[ 999 ]: tensor(45.3890, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def train(i, encoder, states_actions, optimizer_encoder):\n",
    "    encoder.train()\n",
    "    states_actions = states_actions.to(device)\n",
    "    optimizer_encoder.zero_grad()\n",
    "    \n",
    "    current_state_action = torch.clone(states_actions[1:]).to(device).to(device)\n",
    "    next_state = torch.clone(states_actions[:-1, :2]).to(device)\n",
    "    current_state = current_state_action[:,:2]\n",
    "    current_action = current_state_action[:,2:]\n",
    "    \n",
    "    _current_state = encoder(current_state)\n",
    "    _next_state = encoder(next_state)\n",
    "    \n",
    "    _current_state_action = torch.cat((_current_state, current_action), axis=1)\n",
    "    _next_state_predict = predictor(_current_state_action)\n",
    "    \n",
    "    __current_state  = decoder(_current_state)\n",
    "    __next_state = decoder(_next_state)\n",
    "    \n",
    "    loss = mse_loss(_next_state_predict, _next_state) + \\\n",
    "            mse_loss(__current_state, current_state) + \\\n",
    "            mse_loss(__next_state, next_state)\n",
    "    print(\"loss[\", i,\"]:\", loss.mean())\n",
    "    \n",
    "    loss.mean().backward()\n",
    "    optimizer_encoder.step()\n",
    "    \n",
    "    return torch.argmin(loss.mean(axis=1)).type(torch.int)\n",
    "    \n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder = nn.Sequential(\n",
    "                nn.Linear(2,4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4,2),\n",
    "                nn.Sigmoid()).to(device).to(torch.float64)\n",
    "decoder = nn.Sequential(\n",
    "                nn.Linear(2,4),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4,2),\n",
    "                nn.Sigmoid()).to(device).to(torch.float64)\n",
    "predictor = nn.Sequential(\n",
    "                nn.Linear(4,16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16,32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(32,8),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(8,2),\n",
    "                nn.Sigmoid()).to(device).to(torch.float64)\n",
    "\n",
    "optimizer_encoder = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "mse_loss = nn.MSELoss(reduction='none')\n",
    "\n",
    "lowest_loss_index = None\n",
    "for i in range(1000):\n",
    "    momentum_object.step()\n",
    "    states_actions=update_state_buffer(states_actions, lowest_loss_index)\n",
    "    lowest_loss_index = train(i, encoder, states_actions, optimizer_encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"640\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "im = plt.imshow(momentum_object.render(), animated=True)\n",
    "def updatefig(*args):\n",
    "    position = torch.tensor([momentum_object.get_state_action()]).to(device)\n",
    "    predict_position = encoder(position).cpu().detach().numpy()[0]\n",
    "    momentum_object.step()\n",
    "    im.set_array(momentum_object.render(predict_position))\n",
    "ani = FuncAnimation(fig, updatefig, interval=500, blit=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99989771 0.76936865]\n",
      "[0.96353125 0.67160851]\n",
      "[0.89724227 0.67147141]\n",
      "[0.77119219 0.6711651 ]\n",
      "[0.77014911 0.55693823]\n",
      "[0.55611583 0.32529832]\n",
      "[0.55597464 0.32526446]\n",
      "[0.32164272 0.32699519]\n",
      "[0.43527096 0.32574755]\n",
      "[0.55602211 0.32501891]\n",
      "[0.43671023 0.22514227]\n",
      "[0.4457642 0.110193 ]\n",
      "[0.32904494 0.9991435 ]\n",
      "[0.44018009 0.99019879]\n",
      "[0.43995323 0.99014715]\n",
      "[0.43995323 0.99014715]\n",
      "[0.32564901 0.99014945]\n",
      "[0.43370031 0.00382012]\n",
      "[0.44558486 0.11052904]\n",
      "[0.33303576 0.00247311]\n",
      "[0.44810503 1.        ]\n",
      "[0.2262158  0.88820255]\n",
      "[0.32401082 0.7721383 ]\n",
      "[0.22933378 0.67344814]\n",
      "[0.23175572 0.43709529]\n",
      "[0.32794304 0.22605561]\n",
      "[0.33464876 0.11232607]\n",
      "[0.33126836 0.00242148]\n",
      "[0.44810503 1.        ]\n",
      "[0.55872918 0.77143021]\n",
      "[0.43599322 0.88779671]\n",
      "[0.43769416 0.77212218]\n",
      "[0.44032525 0.67214079]\n",
      "[0.3260151  0.67307647]\n",
      "[0.23122742 0.55511823]\n",
      "[0.0013097  0.33116823]\n",
      "[1.         0.33138632]\n",
      "[0.67170247 0.43864389]\n",
      "[0.55754912 0.43880582]\n",
      "[0.32661393 0.22198879]\n",
      "[0.32732766 0.22497006]\n",
      "[0.22432116 0.00259735]\n",
      "[0.10893785 0.11277092]\n",
      "[0.00157847 0.11137478]\n",
      "[1.         0.11242574]\n",
      "[0.96974878 0.99905045]\n",
      "[0.9674958  0.99224028]\n",
      "[0.77248421 0.76764264]\n",
      "[0.55935822 0.55862375]\n",
      "[0.67069595 0.32394434]\n",
      "[0.55743113 0.43906241]\n",
      "[0.55909935 0.55884259]\n",
      "[0.55771453 0.43827374]\n",
      "[0.66924272 0.22824335]\n",
      "[0.55430402 0.22950357]\n",
      "[0.55725356 0.00193674]\n",
      "[0.56239983 0.10842593]\n",
      "[0.44706592 0.99935907]\n",
      "[0.22890416 0.99015175]\n",
      "[0.0016559  0.89394343]\n",
      "[1.         0.98185553]\n",
      "[0.96644595 0.99270992]\n",
      "[0.89424633 0.76762695]\n",
      "[0.96487715 0.55753398]\n",
      "[0.89714045 0.67169997]\n",
      "[0.67336059 0.55818564]\n",
      "[0.77117566 0.67090104]\n",
      "[0.67474177 0.67178686]\n",
      "[0.55928773 0.55860472]\n",
      "[0.4369265  0.43924338]\n",
      "[0.32839109 0.55478011]\n",
      "[0.32622127 0.67272475]\n",
      "[0.43795207 0.77189734]\n",
      "[0.44149634 0.55533386]\n",
      "[0.55625823 0.32456192]\n",
      "[0.32652803 0.22212552]\n",
      "[0.32732766 0.22497006]\n",
      "[0.22356454 0.10828381]\n",
      "[0.10912958 0.00310911]\n",
      "[0.00157344 0.11159186]\n",
      "[0.99943786 0.99916852]\n",
      "[0.77403939 0.99057218]\n",
      "[0.77255179 0.7672432 ]\n",
      "[0.77238367 0.76761512]\n",
      "[0.90120272 0.55685644]\n",
      "[0.90380555 0.43741828]\n",
      "[0.90058519 0.5578919 ]\n",
      "[0.96712868 0.32449077]\n",
      "[0.96805624 0.22912299]\n",
      "[0.90921735 0.22901322]\n",
      "[0.76760908 0.32450202]\n",
      "[0.76772867 0.32402851]\n",
      "[0.55542671 0.11306053]\n",
      "[0.32635625 0.22239916]\n",
      "[0.44624215 0.11070456]\n",
      "[0.55699942 0.99944925]\n",
      "[0.55333858 0.00339526]\n",
      "[0.55751337 0.00196287]\n",
      "[0.44543172 0.00224651]\n",
      "[0.55850061 1.        ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    momentum_object.step()\n",
    "    position = torch.tensor([momentum_object.get_state_action()]).to(device)\n",
    "    predict_position = encoder(position).cpu().detach().numpy()[0]\n",
    "    print(predict_position)\n",
    "    im.set_array(momentum_object.render(predict_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
